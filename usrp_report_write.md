---
marp: true
theme: gaia
paginate: true
math: katex
---
# 學、做、「寫｣
賴敬丰

---
# 目錄
<!-- TOC -->
- [使用 Markdown 和 Marp 的好處](#使用-markdown-和-marp-的好處)
- [擴充](#擴充)
- [實作-建立 Marp 投影片](#實作-建立-marp-投影片)
- [製作 LaTex 以及 Beamer 投影片](#製作-latex-以及-beamer-投影片)
- [實作](#實作)

<!-- /TOC -->

---

# 使用 Markdown 和 Marp 的好處

---
## 使用 Markdown 的好處
###  簡單易學、可讀性高
- 語法直觀，容易上手（例如 `# 標題`、`- 清單`）
- 純文字檔案，易於編輯與版本控制（如 Git）

###  跨平台、工具支援廣
- 幾乎所有文字編輯器都支援 `.md`
- 可轉換成 HTML、PDF、LaTeX 等格式

---

###  適合寫技術文件與筆記
- 支援程式碼區塊 `code block`
- 支援數學公式（結合 KaTeX 或 MathJax）

###  ChatGPT 輸出就是 Markdown

- ChatGPT 回覆的內容是 Markdown 格式

  - 可直接貼入 `.md` 檔使用
  - 可搭配 VS Code、Marp 立即產出文件或簡報
  - 與平時寫的文件無縫接軌
- 這讓 AI 幫你寫文件、做簡報的流程變得簡單


---

## 使用 Marp 的好處（在 Markdown 基礎上）

###  快速製作簡報
- 使用 Markdown 語法就能寫投影片
- 用 `---` 分隔每一張投影片

###  可程式化與版本控制
- 所有投影片內容皆為文字 → 方便用 Git 管理、多人協作
- 適合技術分享、教學、會議簡報

---

###  匯出多種格式
- 可輸出為：
  - HTML（網頁播放）
  - PDF（列印或投影片備份）
  - PPTX (把每頁當作背景輸出，因此輸出後無法更改，但方便美編)

---

##  Markdown + Marp 組合適用情境

| 使用場景         | 傳統工具        | Markdown + Marp 的優勢          |
|------------------|------------------|------------------------------|
| 技術簡報         | PowerPoint       | 快速書寫、支援程式碼/數學公式     |
| 學術/教學投影片  | Keynote/Beamer   | 可寫 LaTeX 且格式統一            |
| 文件寫作         | Word/Google Docs | 輕量、無干擾、可版本控制         |
| 線上協作         | Notion, Docs     | 可配 Git、可直接部署成網頁       |
| 搭配 AI 輸出     | 無法直接接用     | ChatGPT 產出內容可直接套用      |
---

##  小結

- **Markdown** 是寫文件的利器：簡潔、可轉換、易於版本控制。
- **Marp** 則讓 Markdown 變成簡報工具：一份文件 → 簡報、PDF、HTML 多版本。

---

# 擴充
- Markdown
  - Markdown All in One
- Marp
  - Marp for VS Code 
- 如何使用

---
## Markdown All in One

### 為什麼需要它？

- VS Code 雖然內建支援 Markdown，但功能有限：
  - 無法自動補齊清單
  - 無法快速格式化內容
  - 表格對齊麻煩
- **Markdown All in One** 解決這些問題！

---

## 主要功能特色

-  自動清單（Auto List）
-  自動格式化（Format on Save）
-  表格對齊（Table Formatter）
-  快捷鍵支援（快捷鍵可自訂）
- ✅ 標題導航面板（TOC）

---

### 什麼是 TOC？

TOC 是 Table of Contents 的縮寫，即「目錄」。

在 Markdown 文件中，它可以自動根據 `# 標題` 生成一份可點擊的目錄清單，方便快速跳轉。

### TOC 的用途

- 快速了解整份文件結構
- 長文中快速跳轉到指定章節
- 改善可讀性與導覽體驗（尤其在技術文件與教學筆記中）

---

### 如何在 VS Code 中使用 TOC？

1. 使用語法：
  ```
  <!-- TOC -->
  <!-- /TOC -->
  ```

2. 然後使用快捷鍵生成 TOC：
  - Windows/Linux: `Ctrl + Shift + P`→搜尋 `Create Table of Contents`
  - macOS: `Cmd + Shift + P` → 同上

---
# 在 VS Code 安裝所需擴充套件

  
- 點選左側的「Extensions」也可以使用快捷鍵 `Shift + ctrl/command + X`。
-  搜尋 Markdown All in One，點擊 `Install` 安裝。
- 搜尋 Marp for VS Code，點擊 `Install` 安裝。

---
# 實作-建立 Marp 投影片

-建立資料夾及初始化
1.在電腦上建立一個資料夾，假設命名為 marp-slides-demo 或 
2.用 VS Code 開啟這個資料夾（File -> Open Folder...）。

-建立 Markdown 檔案
1.在資料夾中新建一個檔案，例如命名為 example **.md**。
2.在檔案開頭，我們需要一段 front matter 來啟用 Marp 的投影片模式並設定。

---
# 投影片模式設定
---常用的設定:

```
marp: true
theme: gaia
paginate: true
math: katex
---
```

---
# 撰寫投影片內容
---常用到的語法:

# 標題使用 `#`

### 小一點就多放幾個 `#`

- 無序列表使用 `-` 或 `*` 開頭
  * 子項目在前面加上空格 tab

1. 有序列表使用數字加上 `.` 開頭

---

### 表格:使用`|`分隔，第二行加上`-`來分隔表頭與內容 
| 功能 | 說明　| 範例 |      
|-|-|-|
|行內程式碼| 前後加上` (ESC下)  | `ABC` |
|程式碼區塊| 前後加上` ``` ` | ```ABC```|
|斜體     | 前後加上`_`或`*`    | _text_       |
|粗體     | 前後加上`__`或`**`  | **text**     | 
|刪除線   | 前後加上`~~`　　    | ~~text~~     |
|內聯公式 | 前後加上`$`         | $E = mc^2$   |
|區塊公式 | 前後加上`$$`        | $$E = mc^2$$ | 

---

# 輸出投影片內容

View → Command Palette... → 找到 Marp: Export slide deck
或者
`Ctrl+Shift+P` → 找到 Marp: Export slide deck

---

# 製作 LaTex 以及 Beamer 投影片
- Overleaf 
- VS Code 的 LaTeX 環境  




---
# Overleaf
### 創建帳號

1.前往 Overleaf 官網。
2.點擊 Sign up。
3.在Email欄位輸入學校的 .edu 信箱，並設定密碼。
4.按下建立帳號後會跑出驗證。
5.到輸入的信箱確認 Overleaf 寄來的驗證碼。
6.填完資料或skip後就可以開始使用了。

---
# 透過 copilot 轉換 marp (Overleaf)

- 在 Overleaf 左邊的  New Project → Blank Project。
- 開啟要轉換的 marp 頁面，點上方搜尋欄右邊的 Toggle Chat。
- 直接要求把該 marp 轉成 beamer。
- 把結果複製到剛開的 Project。

優點: 快速方便。
缺點: 可能會有格式錯誤、資料不能直接分資料夾放。
- \usepackage{CJKutf8}
- \begin{CJK*}{UTF8}{bsmi} \end{CJK*}

---
# VS code 上直接製作

### VScode配置Latex環境

https://blog.csdn.net/qq_45952740/article/details/131004722


### 下載TeX Live

https://blog.csdn.net/qq_44940689/article/details/140244933

---

# 實作
### 用於 PINN 中的硬嵌入（Hard Constraint Embedding）

---
### PINN 的基本運作原理

PINN 的核心思想:
傳統的神經網路學習依賴大量的標籤數據，而 PINN 的獨到之處在於將物理定律（以 PDE 的形式表示）直接編碼進神經網路的損失函數中。

一個標準的 PINN 模型，其輸入通常是時間和空間座標（例如 $t, x, y$），輸出則是 PDE 的解（例如 $u(t, x, y)$）。其損失函數 $L_{total}$ 主要由兩部分構成：
1.  **物理殘差損失 ($L_{PDE}$)**
2.  **邊界與初始條件損失 ($L_{BC/IC}$)**

---

1.  **物理殘差損失 ($L_{PDE}$)**：衡量神經網路的輸出在多大程度上滿足該 PDE 方程。這通過自動微分技術計算輸出對輸入的各階導數，並將其代入原 PDE 方程得到殘差。理想情況下，一個完美的解會使這個殘差為零。

2.  **邊界與初始條件損失 ($L_{BC/IC}$)**：此項衡量模型的預測值是否符合問題定義的初始條件（Initial Conditions, ICs）和邊界條件（Boundary Conditions, BCs）。

---
總損失函數可表示為：
$$L_{total} = w_{PDE} L_{PDE} + w_{BC/IC} L_{BC/IC}$$
其中 $w_{PDE}$ 和 $w_{BC/IC}$ 是權重係數。訓練的目標就是通過調整神經網路的權重和偏差來最小化 $L_{total}$。

---

## 為什麼 PINN 解帶時間的 PDE 比較困難？
##### -by Gemini 2.5 Pro https://g.co/gemini/share/5857bd61284e

- PINN為求解偏微分方程提供了一種新穎且強大的無網格方法，但在處理包含時間維度的偏微分方程（Time-dependent PDEs）時，往往會面臨比穩態問題（Steady-state problems）更為嚴峻的挑戰。

- 這些困難主要源於時間演化的內在物理特性以及神經網路本身的學習偏好，核心挑戰可歸結為四大方面：**時間因果性的破壞、頻譜偏差、方程的剛性問題，以及長時域積分下的梯度失衡**。

---
### 帶時間 PDE 的核心挑戰
#### 1. 時間因果性（Temporal Causality）的違反

物理系統的演化嚴格遵守因果律：未來狀態由當前和過去的狀態決定。然而，標準的 PINN 在訓練時會從整個時空域中隨機採樣配置點（Collocation points），這意味著網路試圖同時擬合所有時間點的解。

這種「全知」的視角破壞了時間的單向流動性。研究發現，在這種訓練模式下，網路可能會過度關注時間域後期的解，而忽略了從初始條件出發的正確演化路徑，導致在長時間積分問題中累積巨大的誤差，甚至收斂到完全錯誤的解。


---
#### 2. 頻譜偏差（Spectral Bias）

神經網路在訓練過程中存在一個固有的「頻譜偏差」，即它們會優先學習目標函數中的低頻成分，而學習高頻成分則非常困難且緩慢。

許多時間演化問題，尤其是非線性動力學系統（如流體力學中的湍流、波的傳播等），其解在時間和空間上都包含豐富的、跨越多個尺度的高頻成分和複雜結構。PINN 在面對這類問題時，可能只能捕捉到解的平滑、低頻的輪廓，而無法準確還原精細的、快速變化的動態細節。


---
#### 3. 剛性問題（Stiffness）

在微分方程領域，「剛性」（Stiffness）指的是系統中存在多個時間尺度差異巨大的動態過程。例如，在化學反應系統中，某些反應物的濃度可能在微秒級別發生劇變，而另一些則在秒或分鐘級別緩慢變化。

對於傳統的數值求解器而言，剛性問題需要使用特定的隱式積分方法來處理。對於 PINN 來說，這種巨大的尺度差異會導致損失函數中的梯度也出現極大的差異，使得優化過程極其困難。模型很難在一次訓練中同時捕捉到快速和平緩變化的動態，導致訓練失敗。


---
#### 4. 長時域積分下的梯度失衡（Gradient Imbalance）

當求解一個需要長時間積分的 PDE 時，初始條件（在 $t=0$ 時刻）的影響會隨著時間的推移逐漸“稀釋”。

在 PINN 的訓練過程中，這表現為：來自初始條件損失 $L_{IC}$ 的反向傳播梯度，相對於來自整個時空域物理殘差損失 $L_{PDE}$ 的梯度總和，會變得微不足道。優化器因此很難「感知」到初始條件的約束，導致即使 $L_{IC}$ 依然較大，但由於其對總梯度的貢獻很小，網路也無法有效修正。這會造成解從一開始就偏離正確軌道，並隨著時間推移誤差越積越大。


---

## 要怎麼解決?
#####  問 ChatGPT- https://chatgpt.com/share/6861713f-1804-8004-9bb1-c9c85f3a0f07
##### Training PINNs with Hard Constraints and Adaptive Weights: An Ablation Study
###### https://arxiv.org/html/2404.16189v2

這篇文章提供了一項關於硬約束和自適應損失權重的消融研究，研究時間相關偏微分方程的解對其初始條件的依賴性。
研究證明了該方法在1D Cahn-Hilliard和Gray-Scott Equation等不同類型的此類偏微分方程中的有效性。這種方法不僅提高了訓練效率，還提高了學習到的解的準確性和穩定性。

---
## 硬嵌入（Hard Embedding）在 PINN 中的應用
首先，我們需要區分「軟約束」與「硬約束」。

* **軟約束（Soft Constraints）**：這是標準 PINN 的做法。將初始條件和邊界條件作為損失函數的一部分。神經網路的目標是找到一組參數，使總損失函數最小化。但這個方法**無法保證**最終結果能 100% 精確滿足這些條件。

* **硬約束（Hard Constraints）**：不將 IC/BC 放入損失函數，而是直接**修改神經網路的輸出公式**，使其在數學結構上**必然滿足**這些初始和邊界條件。無論神經網路的內部參數如何變化，其最終輸出永遠不會違反這些給定的條件。

---
### 硬約束如何解決梯度失衡問題？

梯度失衡問題的核心在於，總損失函數 $L_{total} = w_{PDE} L_{PDE} + w_{BC/IC} L_{BC/IC}$ 中，不同項的梯度貢獻差異巨大。尤其在長時域問題中，來自初始條件 $L_{IC}$ 的梯度很容易被來自整個時空域的 $L_{PDE}$ 的梯度所「淹沒」，導致優化器無法有效學習初始條件。

---
硬約束通過釜底抽薪的方式解決了這個問題：

1.  **移除損失項**：由於網路的輸出結構已經保證了 IC/BC 的滿足，我們**不再需要 $L_{BC/IC}$ 這個損失項**。總損失函數簡化為 $L_{total} = L_{PDE}$。

2.  **消除梯度競爭**：既然損失函數中只剩下物理殘差項，也就不再存在不同損失項之間的梯度競爭與平衡問題。優化器的唯一目標變得非常純粹：在已經滿足 IC/BC 的解空間中，尋找一個能最小化物理定律殘差的解。

3.  **穩定長時域訓練**：因為初始條件被永久「焊死」在模型結構中，它對整個求解過程的影響不會因為梯度微弱而被忽略。模型從一開始就被迫從正確的初始狀態出發進行演化，這極大地穩定並改善了長時域問題的求解精度。

---
#### 一個簡單的例子：

假設我們要求解一個一維熱傳導方程，其初始條件為 
$$u(t=0, x) = \sin(\pi x)$$

* **硬約束做法**：我們可以設計一個新的輸出形式，例如：
    $$u_{final}(t, x) = \sin(\pi x) + t \cdot \hat{u}_{NN}(t, x)$$
    在這裡，$\hat{u}_{NN}(t, x)$ 是神經網路的直接輸出。請注意，當我們代入 $t=0$ 時，第二項 $t \cdot \hat{u}_{NN}(t, x)$ 直接變為零，因此 $u_{final}(0, x) = \sin(\pi x)$ **恆成立**。這樣，初始條件就被硬編碼進了模型中。

---
### 結論

總結來說，**硬嵌入（硬約束）是一種極其有效的技術，專門用來克服因損失函數項之間競爭而導致的梯度失衡問題**。通過在數學層面強制模型滿足初始和邊界條件，它簡化了優化目標，顯著增強了 PINN 在求解長時域問題時的穩定性和準確性。
